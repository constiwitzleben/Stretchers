{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82cad8db",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "This notebook trains the Stretcher (a small descriptor-adaptation network) on paired SuperPoint descriptors and their transformed counterparts.\n",
    "\n",
    "High-level steps:\n",
    "1) Load a prepared dataset of descriptor pairs and the corresponding affine/strain parameters.\n",
    "2) Build PyTorch DataLoaders for train/val/test.\n",
    "3) Define a small MLP-based model (TripleNet) that fuses descriptors with transformation parameters.\n",
    "4) Train with a cosine-based loss and save the trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5c2fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747e15ec",
   "metadata": {},
   "source": [
    "### Load prepared dataset\n",
    "\n",
    "This notebook assumes you have a precomputed .pth dataset containing: `descriptors` (base descriptors), `deformed_descriptors` (target descriptors after applying an image deformation), and `transformations` (the affine/strain parameters used to transform the keypoint).\n",
    "\n",
    "If you don't have a dataset yet, see `dataset_creation.ipynb` in this repo for an example pipeline that builds these tensors from SuperPoint outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af2ffeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = \"data/SuperPoint_Descriptors_Dataset_Test.pth\"\n",
    "data = torch.load(file_path)\n",
    "\n",
    "base_descriptors = data['descriptors']\n",
    "transformed_descriptors = data['deformed_descriptors']\n",
    "parameters = data['transformations']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aed9af",
   "metadata": {},
   "source": [
    "### Create dataset and dataloaders\n",
    "\n",
    "Wrap the tensors in a `TensorDataset` and split into train/validation/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0ec4b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset and dataloader\n",
    "dataset = TensorDataset(base_descriptors, transformed_descriptors, parameters)\n",
    "# dataset = TensorDataset(all_base_descriptors, all_transformed_descriptors)\n",
    "train_size = 0.7\n",
    "val_size = 0.15\n",
    "test_size = 0.15\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset,[train_size,val_size,test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=512, shuffle=True, drop_last = False, num_workers=32,pin_memory=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False, drop_last = False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, drop_last = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5741cc66",
   "metadata": {},
   "source": [
    "### Model architecture\n",
    "\n",
    "Define a small MLP helper and the `TripleNet`, which fuses descriptor vectors with the transformation parameters. The network adds learned corrections to the input descriptor conditioned on the affine/strain parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6fcd3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim,output_dim,hidden_dim,num_layers):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        if num_layers == 0:\n",
    "            self.model = nn.Linear(input_dim,output_dim)\n",
    "        else:\n",
    "            layers = []\n",
    "            layers.append(nn.Linear(input_dim,hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "            for _ in range(num_layers - 1):\n",
    "                layers.append(nn.Linear(hidden_dim,hidden_dim))\n",
    "                layers.append(nn.ReLU())\n",
    "            \n",
    "            layers.append(nn.Linear(hidden_dim,output_dim))\n",
    "            self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.model(x)\n",
    "\n",
    "class TripleNet(nn.Module):\n",
    "    def __init__(self, descriptor_dim=256, parameter_dim=3, hidden_dim=256, num_layers=2, num_nets=3):\n",
    "        super(TripleNet, self).__init__()\n",
    "        \n",
    "        self.p_scale = nn.Parameter(torch.ones(1))  # Learnable scale parameter\n",
    "        \n",
    "        # Create the first fusion layer\n",
    "        self.mlp_list = nn.ModuleList([MLP(descriptor_dim + parameter_dim, descriptor_dim, hidden_dim, num_layers) \n",
    "                                      for _ in range(num_nets)])\n",
    "        \n",
    "    def forward(self, x, p):\n",
    "        \n",
    "        if torch.all(p==0):\n",
    "            return x\n",
    "        \n",
    "        device = x.device\n",
    "        \n",
    "        # Scale affine parameters to match descriptor magnitude\n",
    "        scaled_p = p * self.p_scale\n",
    "        \n",
    "        # Concatenate descriptor and affine parameters\n",
    "        combined = torch.cat([scaled_p, x], dim=1)\n",
    "        \n",
    "        for mlp in self.mlp_list:\n",
    "            mlp = mlp.to(device)\n",
    "            x += mlp(combined)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38bccbe",
   "metadata": {},
   "source": [
    "### Instantiate model and device\n",
    "\n",
    "Move the model to GPU when available and set input/output dimensions from the loaded tensors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fb260e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "input_dim = base_descriptors.shape[1]\n",
    "output_dim = transformed_descriptors.shape[1]\n",
    "parameter_dim = parameters.shape[1]\n",
    "model = TripleNet(descriptor_dim=input_dim, parameter_dim=parameter_dim, hidden_dim=2048, num_layers=2).to(device).double()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174440b5",
   "metadata": {},
   "source": [
    "### Loss and optimizer\n",
    "\n",
    "We use a cosine-based loss (1 - cosine_similarity) to directly encourage aligned descriptor directions. The notebook sets up an Adam optimizer; adjust learning rate and scheduler as needed for your experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6659cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "def cosine_loss(output,target,reduction = 'mean'):\n",
    "    loss = 1 - torch.nn.functional.cosine_similarity(output,target)\n",
    "\n",
    "    if reduction == 'mean':\n",
    "        return loss.mean()\n",
    "    elif reduction == 'none':\n",
    "        return loss\n",
    "\n",
    "criterion = cosine_loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6a9ae2",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "A straightforward training loop is used: iterate epochs, compute per-sample cosine losses, backpropagate, and evaluate on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d2eb023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/constantinvonwitzleben/miniconda3/envs/fenics/lib/python3.9/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 10 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11, Train Loss: 0.398795, Val Loss: 0.362467\n",
      "Epoch 6/11, Train Loss: 0.301016, Val Loss: 0.342721\n",
      "Epoch 11/11, Train Loss: 0.253727, Val Loss: 0.330493\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 11\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for base, transformed, param in train_dataloader:\n",
    "        base, transformed, param = base.to(device), transformed.to(device), param.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(base, param)\n",
    "        losses = cosine_loss(output,transformed,'none')\n",
    "        loss = losses.mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.extend(losses.cpu().detach().numpy())\n",
    "\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    val_l2s = []\n",
    "    val_cosines = []\n",
    "    with torch.no_grad():\n",
    "        for base, transformed, param in val_dataloader:\n",
    "            base, transformed, param = base.to(device), transformed.to(device), param.to(device)\n",
    "            output = model(base, param)\n",
    "            losses = cosine_loss(output,transformed,'none')\n",
    "            val_losses.extend(losses.cpu().numpy())\n",
    "            \n",
    "    avg_train_loss = np.mean(train_losses)\n",
    "    std_train_loss = np.std(train_losses)\n",
    "\n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    std_val_loss = np.std(val_losses)\n",
    "    \n",
    "    if (epoch)%5 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d2ba81",
   "metadata": {},
   "source": [
    "### Save trained weights\n",
    "\n",
    "At the end we save the model state dict as float32 to `models/stretcher.pth`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a384ca14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete and saved.\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.to(torch.float32).state_dict(), \"models/stretcher.pth\")\n",
    "print(\"Model training complete and saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fenics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
